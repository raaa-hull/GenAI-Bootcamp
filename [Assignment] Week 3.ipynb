{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NraGy9wtq-9M"
      },
      "source": [
        "# **Week 3 Assignment: Building an Advanced RAG System**\n",
        "---\n",
        "\n",
        "### **Objective**\n",
        "\n",
        "The goal of this assignment is to build, evaluate, and iteratively improve a Retrieval-Augmented Generation (RAG) system using a state-of-the-art Large Language Model from Google's Gemini family. You will move beyond a basic pipeline to implement advanced techniques like reranking, with the final application answering complex questions from a real-world financial document.\n",
        "\n",
        "### **Problem Statement**\n",
        "\n",
        "You are an AI Engineer at a top financial services firm. Your team has been tasked with creating a tool to help financial analysts quickly extract key information from lengthy, complex annual reports (10-K filings). Manually searching these 100+ page documents for specific figures or risk assessments is slow and error-prone.\n",
        "\n",
        "Your task is to build a RAG-based Q&A system that allows an analyst to ask natural language questions about a company's 10-K report and receive accurate, grounded answers powered by Gemini.\n",
        "\n",
        "### **Dataset**\n",
        "\n",
        "You will be using the official 2022 10-K annual report for **Microsoft**. A 10-K report is a comprehensive summary of a company's financial performance.\n",
        "*   **Download Link:** [Microsoft Corp. 2022 10-K Report (PDF)](https://www.sec.gov/Archives/edgar/data/789019/000156459022026876/msft-10k_20220630.htm)\n",
        "    *   *Instructions: Go to the link, and save the webpage as a `.txt` file or copy-paste the relevant sections into a text file for easier processing.*\n",
        "\n",
        "---\n",
        "\n",
        "### **Tasks & Instructions**\n",
        "\n",
        "Structure your work in a Jupyter Notebook (`.ipynb`) or Python files. Use markdown cells or comments (in case of Python file-based submissions) to explain your methodology, justify your choices, and present your findings at each stage.\n",
        "\n",
        "**Part 1: Setup and API Configuration**\n",
        "*   **Objective:** To configure your environment to use the Google Gemini API (or an equivalent model).\n",
        "*   **Tasks:**\n",
        "    1.  **Get Your API Key:**\n",
        "        *   Go to [Google AI Studio](https://aistudio.google.com/).\n",
        "        *   Sign in with your Google account.\n",
        "        *   Click on **\"Get API key\"** and create a new API key. **Treat this key like a password and do not share it publicly.**\n",
        "    2.  **Environment Setup:**\n",
        "        *   In your development environment (for example, Google Colab notebook or VSCode on your local machine), install the necessary libraries: `pip install -q -U google-generativeai langchain-google-genai langchain chromadb sentence-transformers`.\n",
        "        *   If you're using Colab, use the \"Secrets\" feature (look for the key icon ğŸ”‘ on the left sidebar) to securely store your API key. Create a new secret named `GEMINI_API_KEY` and paste your key there.\n",
        "    3.  **Configure the LLM:** In your code, import the necessary libraries and configure your LLM. For example, if you're using Colab:\n",
        "        ```python\n",
        "        import google.generativeai as genai\n",
        "        from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "        from google.colab import userdata\n",
        "\n",
        "        # Configure the API key\n",
        "        api_key = userdata.get('GEMINI_API_KEY')\n",
        "        genai.configure(api_key=api_key)\n",
        "\n",
        "        # Instantiate the Gemini model\n",
        "        llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
        "        ```\n",
        "\n",
        "**Part 2: Building the Baseline RAG System**\n",
        "*   **Objective:** To construct a standard, vector-search-only RAG pipeline using Gemini (or an equivalent model) as the generator.\n",
        "*   **Tasks:**\n",
        "    1.  **Document Loading:** Load the Microsoft 10-K report into your application.\n",
        "    2.  **Chunking:** Split the document into chunks. **In a markdown cell (or in a comment, if using Python instead of Jupyter), explicitly state your chosen `chunk_size` and `chunk_overlap` and briefly explain why you chose those values.**\n",
        "    3.  **Vector Store:** Create embeddings for your chunks using an open-source model (e.g., `sentence-transformers/all-MiniLM-L6-v2`) and store them in a vector database (e.g., ChromaDB).\n",
        "    4.  **QA Chain:** Create a standard `RetrievalQA` chain using the `llm` object (Gemini 2.5 Flash or equivalent) you configured in Part 1.\n",
        "    5.  **Initial Test:** Test your baseline system with the following question: `\"What were the company's total revenues for the fiscal year that ended on June 30, 2022?\"`. Display the answer.\n",
        "\n",
        "**Part 3: Evaluating the Baseline**\n",
        "*   **Objective:** To quantitatively and qualitatively assess the performance of your LLM-powered system.\n",
        "*   **Tasks:**\n",
        "    1.  **Create a Test Set:** Create a small evaluation set of at least **five** questions. These questions should be a mix of:\n",
        "        *   **Specific Fact Retrieval:** (e.g., \"What is the name of the company's independent registered public accounting firm?\")\n",
        "        *   **Summarization:** (e.g., \"Summarize the key risks related to competition.\")\n",
        "        *   **Keyword-Dependent:** (e.g., \"What does the report say about 'Azure'?\")\n",
        "    2.  **Qualitative Evaluation:** Run your five questions through the baseline RAG system. For each question, display the generated answer and the source chunks that were retrieved.\n",
        "    3.  **Analysis:** In a markdown cell (or in a comment, if using Python instead of Jupyter), write a brief analysis. Did the system answer correctly? Were the retrieved chunks relevant? Did you notice any failures?\n",
        "\n",
        "**Part 4: Implementing an Advanced RAG Technique**\n",
        "*   **Objective:** To improve upon the baseline by implementing a reranker.\n",
        "*   **Tasks:**\n",
        "    1.  **Implement a Reranker:** Add a reranker (e.g., using `CohereRerank` or a Hugging Face cross-encoder model) into your pipeline. The flow should be: Retrieve top 10 docs -> Rerank to get the best 3 -> Pass only these 3 to LLM for the final answer.\n",
        "    2.  **Re-Evaluation:** Run your same five evaluation questions through your new, advanced RAG pipeline. Display the generated answer and the final source chunks for each.\n",
        "\n",
        "**Part 5: Final Analysis and Conclusion**\n",
        "*   **Objective:** To compare the baseline and advanced systems and articulate the value of the advanced technique.\n",
        "*   **Tasks:**\n",
        "    1.  **Comparison:** In a markdown cell (or in a comment, if using Python instead of Jupyter), create a simple table or a structured list comparing the answers from the **Baseline RAG** vs. the **Advanced RAG** for your five evaluation questions.\n",
        "    2.  **Conclusion:** Write a concluding paragraph answering the following:\n",
        "        *   Did adding the reranker improve the results? How?\n",
        "        *   Based on your experience, what is the biggest challenge in building a reliable RAG system for dense documents?\n",
        "\n",
        "**Bonus Section (Optional)**\n",
        "*   **Objective:** To demonstrate a deeper understanding by implementing more complex features.\n",
        "*   **Choose any of the following to implement:**\n",
        "    *   **Implement Query Rewriting:** Before the retrieval step, use Gemini itself to rewrite the user's query to be more effective for a financial document.\n",
        "    *   **Automated Evaluation with RAGAS:** Use the `ragas` library to automatically score the faithfulness and relevance of your baseline vs. your advanced system.\n",
        "    *   **Source Citing:** Modify your pipeline to not only return the answer but also explicitly cite the source chunk(s) it used.\n",
        "\n",
        "---\n",
        "\n",
        "### **Submission Instructions**\n",
        "\n",
        "1.  **Deadline:** You have **two weeks** from the assignment release date to submit your work.\n",
        "2.  **Platform:** All submissions must be made to your allocated private GitLab repository. You **must** submit your work in a branch named `week_3`.\n",
        "3.  **Format:** You can submit your work as either a Jupyter Notebook (`.ipynb`) or a collection of Python scripts (`.py`).\n",
        "4.  After pushing, you should verify that your branch and files are visible on the GitLab web interface. No further action is needed. The trainers will review all submissions on the `week_3` branch after the deadline. Any assignments submitted after the deadline won't be reviewed and will reflect in your course score.\n",
        "5. The use of LLMs is encouraged, but ensure that youâ€™re not copying solutions blindly. Always review, test, and understand any code generated, adapting it to the specific requirements of your assignment. Your submission should demonstrate your own comprehension, problem-solving process, and coding style, not just an unedited output from an AI tool."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXA0jK346CWZ"
      },
      "source": [
        "## Part 1: Setup and API Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "l-iRudLF6CYW",
        "outputId": "c5aa6387-8e71-4f58-9992-4c421173e7d2"
      },
      "source": [
        "!pip install -U \\\n",
        "  langchain==0.3.27 \\\n",
        "  langchain-core==0.3.72 \\\n",
        "  langchain-text-splitters==0.3.9 \\\n",
        "  langchain-google-genai==2.0.10 \\\n",
        "  langchain-community \\\n",
        "  chromadb \\\n",
        "  sentence-transformers \\\n",
        "  opentelemetry-api==1.37.0 \\\n",
        "  opentelemetry-sdk==1.37.0 \\\n",
        "  opentelemetry-proto==1.37.0 \\\n",
        "  opentelemetry-exporter-otlp-proto-common==1.37.0 \\\n",
        "  opentelemetry-exporter-otlp-proto-http==1.37.0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain==0.3.27 in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Collecting langchain-core==0.3.72\n",
            "  Downloading langchain_core-0.3.72-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting langchain-text-splitters==0.3.9\n",
            "  Downloading langchain_text_splitters-0.3.9-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting langchain-google-genai==2.0.10\n",
            "  Downloading langchain_google_genai-2.0.10-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-1.2.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.1)\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-5.1.2-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: opentelemetry-api==1.37.0 in /usr/local/lib/python3.12/dist-packages (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-sdk==1.37.0 in /usr/local/lib/python3.12/dist-packages (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.37.0 in /usr/local/lib/python3.12/dist-packages (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /usr/local/lib/python3.12/dist-packages (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http==1.37.0 in /usr/local/lib/python3.12/dist-packages (1.37.0)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (0.4.37)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (2.11.10)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (2.0.44)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.3.27) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core==0.3.72) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core==0.3.72) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core==0.3.72) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core==0.3.72) (25.0)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai==2.0.10)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: google-generativeai<0.9.0,>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai==2.0.10) (0.8.5)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api==1.37.0) (8.7.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk==1.37.0) (0.58b0)\n",
            "Requirement already satisfied: protobuf<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-proto==1.37.0) (5.29.5)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http==1.37.0) (1.71.0)\n",
            "INFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.4-py3-none-any.whl.metadata (3.0 kB)\n",
            "  Downloading langchain_community-0.3.31-py3-none-any.whl.metadata (3.0 kB)\n",
            "  Downloading langchain_community-0.3.30-py3-none-any.whl.metadata (3.0 kB)\n",
            "  Downloading langchain_community-0.3.29-py3-none-any.whl.metadata (2.9 kB)\n",
            "  Downloading langchain_community-0.3.28-py3-none-any.whl.metadata (2.9 kB)\n",
            "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.1)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.11.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.3.0)\n",
            "Collecting pybase64>=1.4.1 (from chromadb)\n",
            "  Downloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.38.0)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.75.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.20.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-34.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.3)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.35.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.10) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.10) (2.26.0)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.10) (2.185.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.10) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.10) (1.26.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.10)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api==1.37.0) (3.23.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.3.72) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.27.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Collecting urllib3<2.4.0,>=1.24.2 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.27) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain==0.3.27) (0.25.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.9.23)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\n",
            "INFO: pip is looking at multiple versions of opentelemetry-exporter-otlp-proto-grpc to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.27) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.27) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.27) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.3.27) (3.4.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.27) (3.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.10) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.10) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.10) (4.9.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.10) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.10) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.10) (4.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.10) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.10) (3.2.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai==2.0.10) (0.6.1)\n",
            "Downloading langchain_core-0.3.72-py3-none-any.whl (442 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m442.8/442.8 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.3.9-py3-none-any.whl (33 kB)\n",
            "Downloading langchain_google_genai-2.0.10-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chromadb-1.2.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m20.7/20.7 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentence_transformers-5.1.2-py3-none-any.whl (488 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m488.0/488.0 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m106.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl (19 kB)\n",
            "Downloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (517 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m111.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=14a5d2d23244b6f10d51a1bf7ae8f20b38c4fc71e92813349fb77e76b9c17718\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, filetype, durationpy, uvloop, urllib3, pybase64, mypy-extensions, mmh3, marshmallow, humanfriendly, httptools, bcrypt, backoff, watchfiles, typing-inspect, coloredlogs, posthog, onnxruntime, dataclasses-json, kubernetes, opentelemetry-exporter-otlp-proto-grpc, langchain-core, sentence-transformers, langchain-text-splitters, chromadb, langchain-google-genai, langchain-community\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.79\n",
            "    Uninstalling langchain-core-0.3.79:\n",
            "      Successfully uninstalled langchain-core-0.3.79\n",
            "  Attempting uninstall: sentence-transformers\n",
            "    Found existing installation: sentence-transformers 5.1.1\n",
            "    Uninstalling sentence-transformers-5.1.1:\n",
            "      Successfully uninstalled sentence-transformers-5.1.1\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.11\n",
            "    Uninstalling langchain-text-splitters-0.3.11:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.11\n",
            "Successfully installed backoff-2.2.1 bcrypt-5.0.0 chromadb-1.2.2 coloredlogs-15.0.1 dataclasses-json-0.6.7 durationpy-0.10 filetype-1.2.0 httptools-0.7.1 humanfriendly-10.0 kubernetes-34.1.0 langchain-community-0.3.27 langchain-core-0.3.72 langchain-google-genai-2.0.10 langchain-text-splitters-0.3.9 marshmallow-3.26.1 mmh3-5.2.0 mypy-extensions-1.1.0 onnxruntime-1.23.2 opentelemetry-exporter-otlp-proto-grpc-1.37.0 posthog-5.4.0 pybase64-1.4.2 pypika-0.48.9 sentence-transformers-5.1.2 typing-inspect-0.9.0 urllib3-2.3.0 uvloop-0.22.1 watchfiles-1.1.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              },
              "id": "6abce6921e7e4c78bc288e1b1c8fa7f7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvCB574p6CYw",
        "outputId": "071b2657-4ff3-4a53-f83e-79b709195e0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully imported and configured model\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import google.generativeai as genai\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from google.colab import userdata\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import chromadb\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains.retrieval_qa.base import RetrievalQA\n",
        "from langchain.schema import Document\n",
        "import os\n",
        "import tempfile\n",
        "\n",
        "import os\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = ''\n",
        "os.environ['NO_GCE_CHECK'] = 'True'\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    temperature=0,\n",
        "    max_retries=2\n",
        ")\n",
        "\n",
        "print(\"Successfully imported and configured model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFNJ6c4H6CYy"
      },
      "source": [
        "## Part 2: Building the Baseline RAG System\n",
        "\n",
        "### Step 1: Extract Microsoft 10-K Report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aInbKLN26CY0",
        "outputId": "357d0bae-9ce5-4caa-aead-a829a5350dfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 392,586 characters\n"
          ]
        }
      ],
      "source": [
        "with open('data.txt', 'r', encoding='utf-8') as file:\n",
        "    document_text = file.read()\n",
        "    print(f\"Loaded {len(document_text):,} characters\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgYpAsDK6CZA"
      },
      "source": [
        "### Step 2: Chunking\n",
        "chunk_size = 1000 : Detects enough financial context without mixing other sections.\n",
        "\n",
        "chunk_overlap = 200 : Preserves continuity across chunks and avoids losing context at boundaries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FiDmAqh6CZC",
        "outputId": "82c1b210-0e6f-4e56-f8db-dd205845ce53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created 542 chunks\n"
          ]
        }
      ],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
        "chunks = text_splitter.split_text(document_text)\n",
        "documents = [Document(page_content=chunk, metadata={\"chunk_id\": i}) for i, chunk in enumerate(chunks)]\n",
        "\n",
        "print(f\"Created {len(documents)} chunks\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4wg9dzM6CZZ"
      },
      "source": [
        "### Step 3: Create Vector Store with Embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFiaGXJr6CZb",
        "outputId": "cd59c3b0-d31f-4269-d5bd-ea47a27d0a49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector store created with 542 chunks\n"
          ]
        }
      ],
      "source": [
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "vectorstore = Chroma.from_documents(documents=documents,embedding=embeddings)\n",
        "\n",
        "print(f\"Vector store created with {len(documents)} chunks\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vssgsgx-6CbV"
      },
      "source": [
        "### Step 4: Create Baseline QA Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxa8Ftlv6Cbc",
        "outputId": "039712c6-d0c9-4618-fb1b-264e01c531b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline QA chain created!\n"
          ]
        }
      ],
      "source": [
        "retriever = vectorstore.as_retriever(search_type=\"similarity\",search_kwargs={\"k\": 4})\n",
        "\n",
        "baseline_qa_chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever, return_source_documents=True)\n",
        "\n",
        "print(\"Baseline QA chain created!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rExOMTwZ6CdU"
      },
      "source": [
        "### Step 5: Initial Test - Baseline System"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "0A6H5cTw6CdV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26214120-0975-4e0f-cba3-918875f40bdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What were the company's total revenues for the fiscal year that ended on June 30, 2022?\n",
            "Answer: The company's total revenues for the fiscal year that ended on June 30, 2022, were $28,033.\n",
            "\n",
            "Baseline Sources (4):\n",
            "\n",
            "Source 1:\n",
            "Total\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "$\n",
            "\n",
            "2.48\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "$\n",
            "\n",
            "18,556\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "Fiscal Year 2021\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "...\n",
            "\n",
            "Source 2:\n",
            "Total\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "$\n",
            "\n",
            "2.48\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "$\n",
            "\n",
            "18,556\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "Fiscal Year 2021\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "...\n",
            "\n",
            "Source 3:\n",
            "Total\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "$\n",
            "\n",
            "2.48\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "$\n",
            "\n",
            "18,556\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "Fiscal Year 2021\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "...\n",
            "\n",
            "Source 4:\n",
            "Shares\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "Amount\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "Year Ended June 30,\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "2022\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "2021\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "2020\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "First Quarter\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "21\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "$\n",
            "\n",
            "6,200\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "25\n",
            "\n",
            " \n",
            "\n",
            " ...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_question = \"What were the company's total revenues for the fiscal year that ended on June 30, 2022?\"\n",
        "print(f\"Question: {test_question}\")\n",
        "result = baseline_qa_chain.invoke({\"query\": test_question})\n",
        "print(f\"Answer: {result['result']}\")\n",
        "\n",
        "print(f\"\\nBaseline Sources ({len(result['source_documents'])}):\")\n",
        "for j, doc in enumerate(result[\"source_documents\"]):\n",
        "    print(f\"\\nSource {j+1}:\")\n",
        "    print(doc.page_content[:200] + \"...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kb9BxrQV6CdZ"
      },
      "source": [
        "## Part 3: Evaluating the Baseline System\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "1uKePWaq6Cdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63830cdb-7e2c-4865-fe4c-d5f8ec4cb95c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test 1/5 - Specific Fact Retrieval\n",
            "Question: What is the name of the company's independent registered public accounting firm?\n",
            "Answer:\n",
            "I don't know the answer, as the provided text does not state the name of the independent registered public accounting firm. It only states that \"We have audited...\" but does not identify \"We.\"\n",
            "\n",
            "Sources (4):\n",
            "\n",
            "Source 1:\n",
            "Item 9A\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "REPORT OF INDEPENDENT REGISTERED PUBLIC ACCOUNTING FIRM\n",
            "\n",
            "To the Stockholders and the Board of Directors of Microsoft Corporation\n",
            "\n",
            "Opinion on Internal Control over Financial Reporting\n",
            "\n",
            "W...\n",
            "\n",
            "Source 2:\n",
            "Item 9A\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "REPORT OF INDEPENDENT REGISTERED PUBLIC ACCOUNTING FIRM\n",
            "\n",
            "To the Stockholders and the Board of Directors of Microsoft Corporation\n",
            "\n",
            "Opinion on Internal Control over Financial Reporting\n",
            "\n",
            "W...\n",
            "\n",
            "Source 3:\n",
            "Item 9A\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "REPORT OF INDEPENDENT REGISTERED PUBLIC ACCOUNTING FIRM\n",
            "\n",
            "To the Stockholders and the Board of Directors of Microsoft Corporation\n",
            "\n",
            "Opinion on Internal Control over Financial Reporting\n",
            "\n",
            "W...\n",
            "\n",
            "Source 4:\n",
            "12,734\n",
            "\n",
            " \n",
            "\n",
            "Other countries\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "44,433\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "38,858\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "29,770\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "Total\n",
            "\n",
            " \n",
            "\n",
            "$\n",
            "\n",
            "166,368\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "$\n",
            "\n",
            " 128,314\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "$\n",
            "\n",
            "  ...\n",
            "\n",
            "Test 2/5 - Specific Fact Retrieval\n",
            "Question: What were Microsoft's total revenues for fiscal year 2022?\n",
            "Answer:\n",
            "I don't know the answer. The provided text states that revenue increased by $30.2 billion or 18% in fiscal year 2022 compared to fiscal year 2021, but it does not provide the total revenue amount for fiscal year 2022.\n",
            "\n",
            "Sources (4):\n",
            "\n",
            "Source 1:\n",
            "Highlights from fiscal year 2022 compared with fiscal year 2021 included:\n",
            "\n",
            " \n",
            "\n",
            "â€¢\n",
            "\n",
            "Microsoft Cloud (formerly commercial cloud) revenue increased 32% to $91.2 billion.\n",
            "\n",
            " \n",
            "\n",
            "â€¢\n",
            "\n",
            "Office Commercial products a...\n",
            "\n",
            "Source 2:\n",
            "Highlights from fiscal year 2022 compared with fiscal year 2021 included:\n",
            "\n",
            " \n",
            "\n",
            "â€¢\n",
            "\n",
            "Microsoft Cloud (formerly commercial cloud) revenue increased 32% to $91.2 billion.\n",
            "\n",
            " \n",
            "\n",
            "â€¢\n",
            "\n",
            "Office Commercial products a...\n",
            "\n",
            "Source 3:\n",
            "Highlights from fiscal year 2022 compared with fiscal year 2021 included:\n",
            "\n",
            " \n",
            "\n",
            "â€¢\n",
            "\n",
            "Microsoft Cloud (formerly commercial cloud) revenue increased 32% to $91.2 billion.\n",
            "\n",
            " \n",
            "\n",
            "â€¢\n",
            "\n",
            "Office Commercial products a...\n",
            "\n",
            "Source 4:\n",
            "Fiscal Year 2022 Compared with Fiscal Year 2021\n",
            "\n",
            "Revenue increased $30.2 billion or 18% driven by growth across each of our segments. Intelligent Cloud revenue increased driven by Azure and other clou...\n",
            "\n",
            "Test 3/5 - Summarization\n",
            "Question: Summarize the key risks related to competition mentioned in the report.\n",
            "Answer:\n",
            "The key risks related to competition mentioned in the report are:\n",
            "\n",
            "*   **Government regulatory actions and court decisions:** These can result in fines or hinder the company's ability to provide software benefits, thereby reducing product attractiveness and revenue.\n",
            "*   **New competition law actions:** These could be initiated, potentially using previous actions as precedent.\n",
            "*   **Operational impacts:** To comply with rulings or avoid fines, the company may have to:\n",
            "    *   Withdraw products from certain geographies.\n",
            "    *   Design and develop alternative versions of products, which could lead to delays in product releases.\n",
            "    *   Remove functionality that customers want or on which developers rely.\n",
            "\n",
            "Sources (4):\n",
            "\n",
            "Source 1:\n",
            "OPERATIONAL RISKS...\n",
            "\n",
            "Source 2:\n",
            "OPERATIONAL RISKS...\n",
            "\n",
            "Source 3:\n",
            "OPERATIONAL RISKS...\n",
            "\n",
            "Source 4:\n",
            "30\n",
            "\n",
            "PART I\n",
            "\n",
            "Item 1A\n",
            "\n",
            " \n",
            "\n",
            "Government regulatory actions and court decisions such as these may result in fines or hinder our ability to provide the benefits of our software to consumers and businesses, r...\n",
            "\n",
            "Test 4/5 - Keyword-Dependent\n",
            "Question: What does the report say about Azure's performance and growth?\n",
            "Answer:\n",
            "The report states that Intelligent Cloud revenue increased, driven by **Azure and other cloud services**. It also mentions that Azure and other cloud services revenue includes Nuance cloud services.\n",
            "\n",
            "Sources (4):\n",
            "\n",
            "Source 1:\n",
            "In the first quarter of fiscal year 2022, we made updates to the presentation and method of calculation for certain metrics, most notably changes to incorporate all current and anticipated revenue str...\n",
            "\n",
            "Source 2:\n",
            "In the first quarter of fiscal year 2022, we made updates to the presentation and method of calculation for certain metrics, most notably changes to incorporate all current and anticipated revenue str...\n",
            "\n",
            "Source 3:\n",
            "In the first quarter of fiscal year 2022, we made updates to the presentation and method of calculation for certain metrics, most notably changes to incorporate all current and anticipated revenue str...\n",
            "\n",
            "Source 4:\n",
            "Fiscal Year 2022 Compared with Fiscal Year 2021\n",
            "\n",
            "Revenue increased $30.2 billion or 18% driven by growth across each of our segments. Intelligent Cloud revenue increased driven by Azure and other clou...\n",
            "\n",
            "Test 5/5 - Summarization\n",
            "Question: What are the main segments of Microsoft's business according to the 10-K?\n",
            "Answer:\n",
            "According to the 10-K, the main segments of Microsoft's business are:\n",
            "\n",
            "*   Productivity and Business Processes\n",
            "*   Intelligent Cloud\n",
            "*   More Personal Computing\n",
            "\n",
            "Sources (4):\n",
            "\n",
            "Source 1:\n",
            "â€¢\n",
            "\n",
            "Obsessing over what matters to our customers.\n",
            "\n",
            " \n",
            "\n",
            "â€¢\n",
            "\n",
            "Becoming more diverse and inclusive in everything we do.\n",
            "\n",
            " \n",
            "\n",
            "â€¢\n",
            "\n",
            "Operating as one company, One Microsoft, instead of multiple siloed businesses.\n",
            "...\n",
            "\n",
            "Source 2:\n",
            "â€¢\n",
            "\n",
            "Obsessing over what matters to our customers.\n",
            "\n",
            " \n",
            "\n",
            "â€¢\n",
            "\n",
            "Becoming more diverse and inclusive in everything we do.\n",
            "\n",
            " \n",
            "\n",
            "â€¢\n",
            "\n",
            "Operating as one company, One Microsoft, instead of multiple siloed businesses.\n",
            "...\n",
            "\n",
            "Source 3:\n",
            "â€¢\n",
            "\n",
            "Obsessing over what matters to our customers.\n",
            "\n",
            " \n",
            "\n",
            "â€¢\n",
            "\n",
            "Becoming more diverse and inclusive in everything we do.\n",
            "\n",
            " \n",
            "\n",
            "â€¢\n",
            "\n",
            "Operating as one company, One Microsoft, instead of multiple siloed businesses.\n",
            "...\n",
            "\n",
            "Source 4:\n",
            "10\n",
            "\n",
            "PART I\n",
            "\n",
            "Item 1\n",
            "\n",
            " \n",
            "\n",
            "OPERATING SEGMENTS\n",
            "\n",
            "We operate our business and report our financial performance using three segments: Productivity and Business Processes, Intelligent Cloud, and More Personal ...\n"
          ]
        }
      ],
      "source": [
        "evaluation_questions = [\n",
        "    {\n",
        "        \"question\": \"What is the name of the company's independent registered public accounting firm?\",\n",
        "        \"type\": \"Specific Fact Retrieval\",\n",
        "        \"expected_info\": \"Should find auditor name\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What were Microsoft's total revenues for fiscal year 2022?\",\n",
        "        \"type\": \"Specific Fact Retrieval\",\n",
        "        \"expected_info\": \"Should find exact revenue figure\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Summarize the key risks related to competition mentioned in the report.\",\n",
        "        \"type\": \"Summarization\",\n",
        "        \"expected_info\": \"Should provide overview of competitive risks\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What does the report say about Azure's performance and growth?\",\n",
        "        \"type\": \"Keyword-Dependent\",\n",
        "        \"expected_info\": \"Should find Azure-related information\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What are the main segments of Microsoft's business according to the 10-K?\",\n",
        "        \"type\": \"Summarization\",\n",
        "        \"expected_info\": \"Should identify business segments\"\n",
        "    }\n",
        "]\n",
        "\n",
        "baseline_results = {}\n",
        "\n",
        "for i, eval_item in enumerate(evaluation_questions, 1):\n",
        "    print(f\"\\nTest {i}/5 - {eval_item['type']}\")\n",
        "\n",
        "    question = eval_item['question']\n",
        "    print(f\"Question: {question}\")\n",
        "\n",
        "    result = baseline_qa_chain.invoke({\"query\": question})\n",
        "\n",
        "    print(f\"Answer:\")\n",
        "    print(result[\"result\"])\n",
        "\n",
        "    print(f\"\\nSources ({len(result['source_documents'])}):\")\n",
        "    for j, doc in enumerate(result[\"source_documents\"]):\n",
        "        print(f\"\\nSource {j+1}:\")\n",
        "        print(doc.page_content[:200] + \"...\")\n",
        "\n",
        "    baseline_results[f\"Q{i}\"] = {\n",
        "        \"question\": question,\n",
        "        \"type\": eval_item['type'],\n",
        "        \"answer\": result[\"result\"]\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EjQ9Vhv6Cdc"
      },
      "source": [
        "# Analysis\n",
        "\n",
        "**Score: 3/5**\n",
        "\n",
        "### What worked Good\n",
        "- Found business segments perfectly\n",
        "- Good summaries of risks and competition\n",
        "- Retrieved relevant documents\n",
        "\n",
        "### What Failed\n",
        "- Missed specific facts (auditor name, revenue numbers)\n",
        "- Can't extract exact details from text\n",
        "\n",
        "### Summary\n",
        "The system shows promise for document summarization but needs improvement for precise fact extraction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfv_VqmM6Cdz"
      },
      "source": [
        "## Part 4: Implementing Advanced RAG with Reranking\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "Ih2XDquS6CeA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97e75a80-df8a-4889-ea32-85d45e0f609b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test 1/5 - Specific Fact Retrieval\n",
            "Question: What is the name of the company's independent registered public accounting firm?\n",
            "Answer:I don't know the answer. The provided text states that an independent registered public accounting firm audited Microsoft Corporation, but it does not name the firm.\n",
            "\n",
            "Cohere Reranked Sources (3):\n",
            "\n",
            "Source 1:\n",
            "Item 9A\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "REPORT OF INDEPENDENT REGISTERED PUBLIC ACCOUNTING FIRM\n",
            "\n",
            "To the Stockholders and the Board of Directors of Microsoft Corporation\n",
            "\n",
            "Opinion on Internal Control over Financial Reporting\n",
            "\n",
            "W...\n",
            "\n",
            "Source 2:\n",
            "Item 9A\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "REPORT OF INDEPENDENT REGISTERED PUBLIC ACCOUNTING FIRM\n",
            "\n",
            "To the Stockholders and the Board of Directors of Microsoft Corporation\n",
            "\n",
            "Opinion on Internal Control over Financial Reporting\n",
            "\n",
            "W...\n",
            "\n",
            "Source 3:\n",
            "Item 9A\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "REPORT OF INDEPENDENT REGISTERED PUBLIC ACCOUNTING FIRM\n",
            "\n",
            "To the Stockholders and the Board of Directors of Microsoft Corporation\n",
            "\n",
            "Opinion on Internal Control over Financial Reporting\n",
            "\n",
            "W...\n",
            "\n",
            "Test 2/5 - Specific Fact Retrieval\n",
            "Question: What were Microsoft's total revenues for fiscal year 2022?\n",
            "Answer:I don't know the answer to Microsoft's total revenues for fiscal year 2022. The provided text only states that revenue increased by $30.2 billion or 18% in fiscal year 2022 compared to fiscal year 2021, but it does not provide the absolute total revenue for either year.\n",
            "\n",
            "Cohere Reranked Sources (3):\n",
            "\n",
            "Source 1:\n",
            "Fiscal Year 2022 Compared with Fiscal Year 2021\n",
            "\n",
            "Revenue increased $30.2 billion or 18% driven by growth across each of our segments. Intelligent Cloud revenue increased driven by Azure and other clou...\n",
            "\n",
            "Source 2:\n",
            "Fiscal Year 2022 Compared with Fiscal Year 2021\n",
            "\n",
            "Revenue increased $30.2 billion or 18% driven by growth across each of our segments. Intelligent Cloud revenue increased driven by Azure and other clou...\n",
            "\n",
            "Source 3:\n",
            "Fiscal Year 2022 Compared with Fiscal Year 2021\n",
            "\n",
            "Revenue increased $30.2 billion or 18% driven by growth across each of our segments. Intelligent Cloud revenue increased driven by Azure and other clou...\n",
            "\n",
            "Test 3/5 - Summarization\n",
            "Question: Summarize the key risks related to competition mentioned in the report.\n",
            "Answer:The key risks related to competition mentioned in the report are:\n",
            "\n",
            "*   **Fines and Reduced Revenue:** Government regulatory actions and court decisions can result in fines and hinder the ability to provide software benefits, thereby reducing product attractiveness and revenue.\n",
            "*   **New Competition Law Actions:** Previous actions could set a precedent for new competition law actions.\n",
            "*   **Product Withdrawal or Alteration:** The company may have to choose between withdrawing products from certain geographies to avoid fines or designing and developing alternative versions to comply with government rulings.\n",
            "*   **Product Release Delays:** Developing alternative product versions for compliance may entail delays in product releases.\n",
            "*   **Loss of Functionality:** Compliance could require removing functionality that customers want or on which developers rely.\n",
            "\n",
            "Cohere Reranked Sources (3):\n",
            "\n",
            "Source 1:\n",
            "30\n",
            "\n",
            "PART I\n",
            "\n",
            "Item 1A\n",
            "\n",
            " \n",
            "\n",
            "Government regulatory actions and court decisions such as these may result in fines or hinder our ability to provide the benefits of our software to consumers and businesses, r...\n",
            "\n",
            "Source 2:\n",
            "30\n",
            "\n",
            "PART I\n",
            "\n",
            "Item 1A\n",
            "\n",
            " \n",
            "\n",
            "Government regulatory actions and court decisions such as these may result in fines or hinder our ability to provide the benefits of our software to consumers and businesses, r...\n",
            "\n",
            "Source 3:\n",
            "30\n",
            "\n",
            "PART I\n",
            "\n",
            "Item 1A\n",
            "\n",
            " \n",
            "\n",
            "Government regulatory actions and court decisions such as these may result in fines or hinder our ability to provide the benefits of our software to consumers and businesses, r...\n",
            "\n",
            "Test 4/5 - Keyword-Dependent\n",
            "Question: What does the report say about Azure's performance and growth?\n",
            "Answer:The report indicates the following about Azure's performance and growth:\n",
            "\n",
            "*   **Gross Margin Growth:** Gross margin increased by $9.4 billion or 22%, driven by growth in Azure and other cloud services.\n",
            "*   **Gross Margin Percentage:** Excluding the impact of a change in accounting estimate, the gross margin percentage was relatively unchanged, driven by improvement in Azure and other cloud services, though this was partially offset by a sales mix shift to Azure and other cloud services.\n",
            "*   **Operating Expenses:** Operating expenses increased by $2.8 billion or 16%, driven by investments in Azure and other cloud services.\n",
            "\n",
            "Cohere Reranked Sources (3):\n",
            "\n",
            "Source 1:\n",
            "â€¢\n",
            "\n",
            "Enterprise Services revenue increased $464 million or 7% driven by growth in Enterprise Support Services.\n",
            "\n",
            "Operating income increased $6.6 billion or 25%.\n",
            "\n",
            " \n",
            "\n",
            "â€¢\n",
            "\n",
            "Gross margin increased $9.4 billion...\n",
            "\n",
            "Source 2:\n",
            "â€¢\n",
            "\n",
            "Enterprise Services revenue increased $464 million or 7% driven by growth in Enterprise Support Services.\n",
            "\n",
            "Operating income increased $6.6 billion or 25%.\n",
            "\n",
            " \n",
            "\n",
            "â€¢\n",
            "\n",
            "Gross margin increased $9.4 billion...\n",
            "\n",
            "Source 3:\n",
            "â€¢\n",
            "\n",
            "Enterprise Services revenue increased $464 million or 7% driven by growth in Enterprise Support Services.\n",
            "\n",
            "Operating income increased $6.6 billion or 25%.\n",
            "\n",
            " \n",
            "\n",
            "â€¢\n",
            "\n",
            "Gross margin increased $9.4 billion...\n",
            "\n",
            "Test 5/5 - Summarization\n",
            "Question: What are the main segments of Microsoft's business according to the 10-K?\n",
            "Answer:According to the 10-K, Microsoft operates its business and reports its financial performance using three segments:\n",
            "\n",
            "*   Productivity and Business Processes\n",
            "*   Intelligent Cloud\n",
            "*   More Personal Computing\n",
            "\n",
            "Cohere Reranked Sources (3):\n",
            "\n",
            "Source 1:\n",
            "10\n",
            "\n",
            "PART I\n",
            "\n",
            "Item 1\n",
            "\n",
            " \n",
            "\n",
            "OPERATING SEGMENTS\n",
            "\n",
            "We operate our business and report our financial performance using three segments: Productivity and Business Processes, Intelligent Cloud, and More Personal ...\n",
            "\n",
            "Source 2:\n",
            "10\n",
            "\n",
            "PART I\n",
            "\n",
            "Item 1\n",
            "\n",
            " \n",
            "\n",
            "OPERATING SEGMENTS\n",
            "\n",
            "We operate our business and report our financial performance using three segments: Productivity and Business Processes, Intelligent Cloud, and More Personal ...\n",
            "\n",
            "Source 3:\n",
            "10\n",
            "\n",
            "PART I\n",
            "\n",
            "Item 1\n",
            "\n",
            " \n",
            "\n",
            "OPERATING SEGMENTS\n",
            "\n",
            "We operate our business and report our financial performance using three segments: Productivity and Business Processes, Intelligent Cloud, and More Personal ...\n"
          ]
        }
      ],
      "source": [
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.retrievers.document_compressors import CohereRerank\n",
        "\n",
        "cohere_api_key = userdata.get('COHERE_API_KEY')\n",
        "\n",
        "base_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})\n",
        "\n",
        "compressor = CohereRerank(cohere_api_key=cohere_api_key,model=\"rerank-english-v3.0\")\n",
        "\n",
        "reranked_retriever = ContextualCompressionRetriever(base_compressor=compressor,base_retriever=base_retriever)\n",
        "\n",
        "advanced_qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=reranked_retriever,\n",
        "    return_source_documents=True\n",
        ")\n",
        "\n",
        "for i, eval_item in enumerate(evaluation_questions, 1):\n",
        "    print(f\"\\nTest {i}/5 - {eval_item['type']}\")\n",
        "\n",
        "    question = eval_item['question']\n",
        "    print(f\"Question: {question}\")\n",
        "\n",
        "    result = advanced_qa_chain.invoke({\"query\": question})\n",
        "\n",
        "    print(f\"Answer:{result[\"result\"]}\")\n",
        "\n",
        "    print(f\"\\nCohere Reranked Sources ({len(result['source_documents'])}):\")\n",
        "    for j, doc in enumerate(result[\"source_documents\"]):\n",
        "        print(f\"\\nSource {j+1}:\")\n",
        "        print(doc.page_content[:200] + \"...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwrBt5Af6CeT"
      },
      "source": [
        "## Part 5: Final Analysis and Conclusion\n",
        "\n",
        "###**Analysis**\n",
        "\n",
        "| Test | Type                              | Baseline RAG                | Advanced RAG (with Reranker)          | Result             |\n",
        "| ---- | --------------------------------- | --------------------------- | ------------------------------------- | ------------------ |\n",
        "| 1    | Fact â€“ Accounting firm            | Couldnâ€™t find firm name     | Same, but retrieved more focused text | Slight improvement |\n",
        "| 2    | Fact â€“ Revenue 2022               | Found % growth only         | Same result                           | No major change    |\n",
        "| 3    | Summarization â€“ Competition risks | Correct but brief           | More complete and clear               | Better summary     |\n",
        "| 4    | Keyword â€“ Azure growth            | General info                | More focused and detailed             | Improved accuracy  |\n",
        "| 5    | Summarization â€“ Business segments | Correct but with extra info | Cleaner and precise                   | Improved relevance |\n",
        "\n",
        "###**Conclusion**\n",
        "The advanced RAG system produced more detailed and focused answers by retrieving more relevant context compared to the baseline. It showed clear improvement in summarization and context-heavy questions, offering better organization and precision. However, it still struggled with specific factual details like company names or exact figures when those facts werenâ€™t present in the retrieved text. Overall, adding the reranker improved relevance and answer quality but didnâ€™t fully solve the challenge of missing exact facts in dense documents.\n",
        "\n",
        "###**Biggest Challenge**\n",
        "Getting specific facts from long, complex documents. While the system can find the right sections, it often struggles to extract exact detailsâ€”like company names or revenue numbersâ€”because key information may be split across chunks or partially missed during retrieval."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IG-nMvbb6CfU"
      },
      "source": [
        "## Bonus Section: Advanced Features (Optional)\n",
        "\n",
        "### Query Rewriting with Gemini\n",
        "\n",
        "This bonus feature uses Gemini itself to rewrite user queries to be more effective for financial document search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "8zND9fb06CfV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc4e3260-3d15-4b7b-c412-e4e3200a39aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Question: How much money did the company make last year?\n",
            "Rewritten Query: Retrieve the company's **net income** (or **net earnings** / **profit**) for the **most recent fiscal year** as reported in the **Consolidated Statements of Operations** (or **Income Statement**) within its **annual 10-K filing**. Additionally, identify the **total revenue** for the same period.\n",
            "Answer:\n",
            "Answer:I'm sorry, but the provided text does not contain the company's net income (or net earnings/profit) or total revenue for the most recent fiscal year. The text discusses critical accounting estimates and recent accounting guidance, but it does not include the actual financial figures from the Consolidated Statements of Operations.\n",
            "\n",
            "Source Citations (3):\n",
            "\n",
            "[Citation 1]:\n",
            "Content: RECENT ACCOUNTING GUIDANCE\n",
            "\n",
            "Refer to Note 1 â€“ Accounting Policies of the Notes to Financial Statements (Part II, Item 8 of this Form 10-K) for further discussion.\n",
            "\n",
            "CRITICAL ACCOUNTING ESTIMATES\n",
            "\n",
            "Our c...\n",
            "\n",
            "[Citation 2]:\n",
            "Content: RECENT ACCOUNTING GUIDANCE\n",
            "\n",
            "Refer to Note 1 â€“ Accounting Policies of the Notes to Financial Statements (Part II, Item 8 of this Form 10-K) for further discussion.\n",
            "\n",
            "CRITICAL ACCOUNTING ESTIMATES\n",
            "\n",
            "Our c...\n",
            "\n",
            "[Citation 3]:\n",
            "Content: RECENT ACCOUNTING GUIDANCE\n",
            "\n",
            "Refer to Note 1 â€“ Accounting Policies of the Notes to Financial Statements (Part II, Item 8 of this Form 10-K) for further discussion.\n",
            "\n",
            "CRITICAL ACCOUNTING ESTIMATES\n",
            "\n",
            "Our c...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "original_question = \"How much money did the company make last year?\"\n",
        "print(f\"Original Question: {original_question}\")\n",
        "\n",
        "rewrite_prompt = f\"\"\"\n",
        "You are an expert at searching financial documents like 10-K reports.\n",
        "Rewrite the following user query to be more effective for document retrieval.\n",
        "\n",
        "Guidelines:\n",
        "- Add relevant financial terminology\n",
        "- Include context about annual reports/10-K filings\n",
        "- Make the query more specific and searchable\n",
        "- Keep the original intent\n",
        "\n",
        "Original query: \"{original_question}\"\n",
        "\n",
        "Rewritten query:\n",
        "\"\"\"\n",
        "\n",
        "response = llm.invoke(rewrite_prompt)\n",
        "rewritten_query = response.content.strip()\n",
        "print(f\"Rewritten Query: {rewritten_query}\")\n",
        "search_query = rewritten_query\n",
        "\n",
        "result = advanced_qa_chain.invoke({\"query\": search_query})\n",
        "\n",
        "print(f\"Answer:\")\n",
        "print(f\"Answer:{result[\"result\"]}\")\n",
        "\n",
        "print(f\"\\nSource Citations ({len(result['source_documents'])}):\")\n",
        "\n",
        "for i, doc in enumerate(result[\"source_documents\"]):\n",
        "    print(f\"\\n[Citation {i+1}]:\")\n",
        "    print(f\"Content: {doc.page_content[:200]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if vectorstore has diverse content\n",
        "print(\"ğŸ” Checking document diversity:\")\n",
        "test_search = vectorstore.similarity_search(\"total revenue fiscal year 2022\", k=10)\n",
        "for i, doc in enumerate(test_search):\n",
        "    print(f\"Doc {i+1}: {doc.page_content[:100]}...\")\n",
        "    print(f\"Metadata: {doc.metadata}\")\n",
        "    print(\"-\" * 40)"
      ],
      "metadata": {
        "id": "b9VLh-1BmR18",
        "outputId": "12abe505-3182-41a4-d120-3e1ba4d33502",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ” Checking document diversity:\n",
            "Doc 1: Total\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "$\n",
            "\n",
            "2.48\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "$\n",
            "\n",
            "18,556\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " ...\n",
            "Metadata: {'chunk_id': 467}\n",
            "----------------------------------------\n",
            "Doc 2: Total\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "$\n",
            "\n",
            "2.48\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "$\n",
            "\n",
            "18,556\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " ...\n",
            "Metadata: {'chunk_id': 467}\n",
            "----------------------------------------\n",
            "Doc 3: Total\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "$\n",
            "\n",
            "2.48\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "$\n",
            "\n",
            "18,556\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " ...\n",
            "Metadata: {'chunk_id': 467}\n",
            "----------------------------------------\n",
            "Doc 4: 19,439\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "15,911\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "Tot...\n",
            "Metadata: {'chunk_id': 486}\n",
            "----------------------------------------\n",
            "Doc 5: 19,439\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "15,911\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "Tot...\n",
            "Metadata: {'chunk_id': 486}\n",
            "----------------------------------------\n",
            "Doc 6: 19,439\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "15,911\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "Tot...\n",
            "Metadata: {'chunk_id': 486}\n",
            "----------------------------------------\n",
            "Doc 7: 2022\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "2021\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "2020\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "Accounts receivable, net of all...\n",
            "Metadata: {'chunk_id': 350}\n",
            "----------------------------------------\n",
            "Doc 8: 2022\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "2021\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "2020\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "Accounts receivable, net of all...\n",
            "Metadata: {'chunk_id': 350}\n",
            "----------------------------------------\n",
            "Doc 9: 2022\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "2021\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "2020\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "Accounts receivable, net of all...\n",
            "Metadata: {'chunk_id': 350}\n",
            "----------------------------------------\n",
            "Doc 10: Shares\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "Amount\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "Year Ended June 30,\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "2022\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "202...\n",
            "Metadata: {'chunk_id': 463}\n",
            "----------------------------------------\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}